{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing of Logs\n",
    "\n",
    "\n",
    "\n",
    "#### 1.- Reading and writing logs\n",
    "\n",
    "#### 2.- NLP Techniques applied to logs\n",
    "\n",
    "    2.1.- Sentence detection\n",
    "\n",
    "    2.2.- Part-Of-Speech Taging\n",
    "\n",
    "    2.3.- Named Entities Recognition\n",
    "\n",
    "    2.4.- Acronym detection\n",
    "\n",
    "    2.5.- Dependency Parser\n",
    "\n",
    "    2.6.- Lemmatization\n",
    "\n",
    "#### 3.- Clustering\n",
    "\n",
    "    3.1.- DBSCAN algorithm\n",
    "    \n",
    "    3.2.- Computation of clusters\n",
    "    \n",
    "    3.3.- Evaluation of clusters\n",
    "\n",
    "#### 4.- Text Quality metrics\n",
    "#### 5.- Creation of the new log and re-labelling of events\n",
    "#### 6.- Data Log Quality Metrics Calculation\n",
    "#### 7.- Process Quality Metrics Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Reading and writting CSV logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "LOG_FILE_PATH=\"./data/original_log.csv\"\n",
    "\n",
    "def read_csv_log(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        row = next(reader)\n",
    "        if len(row) == 3:\n",
    "            return [(inc_code, inc_type, description) for inc_code, inc_type, description in reader]\n",
    "        else:\n",
    "            return [(inc_code, description) for inc_code, description in reader]\n",
    "\n",
    "    \n",
    "def write_csv_log(log, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        for line in log:\n",
    "            writer.writerow(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incidences:  4416\n"
     ]
    }
   ],
   "source": [
    "incidences = read_csv_log(LOG_FILE_PATH)\n",
    "\n",
    "print(\"Number of incidences: \", len(incidences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incidences by type:\n",
      "\tTYPE \t INCIDENCES\n",
      "\t TT \t   1775\n",
      "\t NHA \t   1287\n",
      "\t HEQ \t   185\n",
      "\t PIS \t   40\n",
      "\t NHM \t   212\n",
      "\t HMC \t   33\n",
      "\t PIO \t   383\n",
      "\t HEL \t   196\n",
      "\t NHP \t   33\n",
      "\t NHT \t   272\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "type_counter = Counter([inc_type for _, inc_type, _ in incidences])\n",
    "\n",
    "print(\"Number of incidences by type:\")\n",
    "print(\"\\tTYPE \\t INCIDENCES\")\n",
    "for itype, count in type_counter.items():\n",
    "    print(\"\\t %s \\t   %d\" %(itype, count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- NLP Techniques applied to logs\n",
    "\n",
    "Loading NLP resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('es_core_news_md')  # Language model for Spanish\n",
    "\n",
    "stopwords = [\"warning\", \"warning:\"]  # words that occur in the logs and do not provide any information\n",
    "\n",
    "docs = {code:nlp(text) for code, _, text in incidences}\n",
    "tokens = {code: [t for t in doc] for code, doc in docs.items()}\n",
    "\n",
    "# Pre-process incidences\n",
    "raw_texts = [str(token) for _, token in tokens.items()]  # without NLP filters\n",
    "codes = [code for code, _ in tokens.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.- Sentence Detection\n",
    "\n",
    "The trained language models provided by SpaCy include all the requirements for our approach, including a simple, yet useful, sentence detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[[Se aborta para TS], [WARNING: no tenemos masa en el pin 1], [SE aborta para relanzar de nuevo], [WARNING: se comprueba la funcionalidad del X-lock cambiado siendo correcta ,asi como su indicación el la LMCP ,LMWS ,SWLP Y FWS Y ECAM .], [se aborta para configurar avion]]\n"
     ]
    }
   ],
   "source": [
    "sentences = {code:list(doc.sents) for code, doc in docs.items()}\n",
    "\n",
    "print(list(sentences.keys())[:5])\n",
    "print(list(sentences.values())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.- POS Tagging\n",
    "\n",
    "The logs are processed in order to keep just those words with a specific morphosyntactic category in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[['aborta', 'TS'], ['WARNING', 'tenemos', 'masa', 'pin'], ['aborta', 'relanzar', 'nuevo'], ['WARNING', 'comprueba', 'funcionalidad', 'X', 'lock', 'cambiado', 'correcta', 'indicación', 'LMCP', 'LMWS', 'SWLP', 'FWS', 'ECAM'], ['aborta', 'configurar', 'avion']]\n"
     ]
    }
   ],
   "source": [
    "TAGS = {\"NOUN\", \"VERB\", \"ADJ\", \"PROPN\"}    # we want to keep those words classified with these tags\n",
    "\n",
    "postags = {code:[str(token) for token in tks if token.pos_ in TAGS] for code, tks in tokens.items()}\n",
    "\n",
    "print(list(postags.keys())[:5])\n",
    "print(list(postags.values())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.- Named Entities Recognition (NER)\n",
    "\n",
    "Named entities are words or groups of words that refers to an organization, a specific person or location, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[[], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "entities = {code:[str(token) for token in tokens if token in set(docs[code].ents)] for code, tks in tokens.items()}\n",
    "\n",
    "print(list(entities.keys())[:5])\n",
    "print(list(entities.values())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.- Acronym Detection\n",
    "\n",
    "A simple rule-based approach: a word is considered an **acronym** if it's uppercased and it does not appear in the vocabulary of the target language (in lowercases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def detect_acronyms(inc_tokens):\n",
    "    return [str(token) for token in set(inc_tokens) if str(token).isupper() and str(token).lower() not in nlp.vocab and len(str(token)) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[[], [], [], ['SWLP', 'LMCP', 'FWS', 'LMWS'], []]\n"
     ]
    }
   ],
   "source": [
    "acronyms = {code:detect_acronyms(tks) for code, tks in tokens.items()}\n",
    "\n",
    "print(list(acronyms.keys())[:5])\n",
    "print(list(acronyms.values())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.- Dependency Parser\n",
    "\n",
    "The words in the log are filtered out, keeping just those words with a specific function in the text (_subject, direct object, root,_ etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "DEPENDENCIES = {\"nsubj\", \"obj\"}     # Set of dependencies that we want to keep. \n",
    "                                    # We could be (a lot) more restrictive with: DEPENDENCIES = {\"ROOT\"}\n",
    "\n",
    "def dependencies(inc_tokens, dependencies=DEPENDENCIES):\n",
    "    valids = set()\n",
    "    for token in inc_tokens:\n",
    "        if token.dep_ in dependencies:\n",
    "            valids.add(str(token))              # Token with the required dependency\n",
    "            valids.add(str(token.head))         # Token that is the origin of this dependency\n",
    "    \n",
    "    return [str(token) for token in inc_tokens if str(token) in valids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[['Se', 'aborta'], ['tenemos', 'masa'], ['SE', 'aborta'], ['se', 'comprueba', 'funcionalidad', 'asi', 'indicación'], ['se', 'aborta', 'configurar', 'avion']]\n"
     ]
    }
   ],
   "source": [
    "deps = {code:dependencies(tks) for code, tks in tokens.items()}\n",
    "\n",
    "print(list(deps.keys())[:5])\n",
    "print(list(deps.values())[:5])\n",
    "\n",
    "deps_root = {code:dependencies(tks, {\"ROOT\"}) for code, tks in tokens.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.- Lemmatization\n",
    "\n",
    "Logs where the words are changed by their lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007314995715', '1010259490543', '1014902821262', '1015282934226', '1017842527711']\n",
      "[['Se', 'abortar', 'parir', 'TS'], ['WARNING', ':', 'no', 'tener', 'masa', 'en', 'el', 'pin', '1'], ['SE', 'abortar', 'parir', 'relanzar', 'de', 'nuevo'], ['WARNING', ':', 'se', 'comprobar', 'lo', 'funcionalidad', 'del', 'X', '-', 'lock', 'cambiar', 'ser', 'correcto', ',', 'asi', 'comer', 'su', 'indicación', 'el', 'lo', 'LMCP', ',', 'LMWS', ',', 'SWLP', 'Y', 'FWS', 'Y', 'ECAM', '.'], ['se', 'abortar', 'parir', 'configurar', 'avion']]\n"
     ]
    }
   ],
   "source": [
    "lemmas = {code:[token.lemma_ for token in tks] for code, tks in tokens.items()}\n",
    "\n",
    "print(list(lemmas.keys())[:5])\n",
    "print(list(lemmas.values())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Clustering\n",
    "\n",
    "### 3.1.- DBSCAN algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def cluster_incidences(texts, inc_codes=codes):\n",
    "    # Clustering model\n",
    "    model = DBSCAN(n_jobs=2)\n",
    "\n",
    "    # Vectorization of the texts\n",
    "    vectorizer = TfidfVectorizer(stop_words=list(STOP_WORDS), max_df=0.95, min_df=1, lowercase=True)\n",
    "    vec_model = vectorizer.fit_transform(texts)\n",
    "\n",
    "    # compute clusters\n",
    "    topics = model.fit_predict(vec_model)\n",
    "\n",
    "    return {code: topic for code, topic in zip(inc_codes, topics)}, vec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.- Computation of clusters for the different NLP pre-processed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Raw texts\n",
    "raw_text_clusters, raw_texts_vecmodel = cluster_incidences(raw_texts)\n",
    "\n",
    "# POS-Tagging\n",
    "pos_texts = [\" \".join(t) for _,t in postags.items()]\n",
    "pos_clustering, pos_vecmodel = cluster_incidences(pos_texts)\n",
    "\n",
    "# Dependencies: nsubj and obj\n",
    "deps_texts = [\" \".join(t) for _,t in deps.items()]\n",
    "deps_clustering, deps_vecmodel = cluster_incidences(deps_texts)\n",
    "\n",
    "# Dependencies: ROOT\n",
    "root_texts = [\" \".join(t) for _,t in deps_root.items()]\n",
    "root_clustering, root_vecmodel = cluster_incidences(root_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.- Evaluation of clusters with silhouette metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def silhouette_computation(vec_model, topics):\n",
    "    return silhouette_score(vec_model, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Raw texts => Silhouette metric: -0.038807\n"
     ]
    }
   ],
   "source": [
    "# Raw texts\n",
    "silhouette_raw = silhouette_score(raw_texts_vecmodel, list(raw_text_clusters.values()))\n",
    "print(\"* Raw texts => Silhouette metric: %f\" % silhouette_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* POS tagged texts => Silhouette metric: -0.019892\n"
     ]
    }
   ],
   "source": [
    "# POS-Tagging: NOUN, VERB, NPROP, ADJ\n",
    "silhouette_pos = silhouette_score(pos_vecmodel, list(pos_clustering.values()))\n",
    "print(\"* POS tagged texts => Silhouette metric: %f\" % silhouette_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Dependency parsed texts => Silhouette metric: 0.238413\n"
     ]
    }
   ],
   "source": [
    "# Dependency parser: nsubvj, obj\n",
    "silhouette_deps = silhouette_score(deps_vecmodel, list(deps_clustering.values()))\n",
    "print(\"* Dependency parsed texts => Silhouette metric: %f\" % silhouette_deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Dependency parsed texts (ROOT) => Silhouette metric: 0.685790\n"
     ]
    }
   ],
   "source": [
    "# Dependency parser: ROOT\n",
    "silhouette_root = silhouette_score(root_vecmodel, list(root_clustering.values()))\n",
    "print(\"* Dependency parsed texts (ROOT) => Silhouette metric: %f\" % silhouette_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Text Quality Metrics\n",
    "\n",
    "Set of metrics computed in order to assess the quality of the data logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Reading data log files\n",
    "log_dep_lemmas_root = read_csv_log('./data/log_sentences_dep_lemmas_root.csv')\n",
    "text_dep_lemmas_root = [\"\".join(t) for _,t in log_dep_lemmas_root]\n",
    "\n",
    "log_dep_lemmas = read_csv_log('./data/log_sentences_dependencies_lemmas.csv')\n",
    "text_dep_lemmas = [\"\".join(t) for _,t in log_dep_lemmas]\n",
    "\n",
    "log_pos_ner_acronyms_lemmas = read_csv_log('./data/log_sentences_pos_ner_acronyms_lemma.csv')\n",
    "text_pos_ner_acronyms_lemmas = [\"\".join(t) for _,t in log_pos_ner_acronyms_lemmas]\n",
    "\n",
    "log_pos_ner_acronyms = read_csv_log('./data/log_sentences_pos_ner_acronyms.csv')\n",
    "text_pos_ner_acronyms = [\"\".join(t) for _,t in log_pos_ner_acronyms]\n",
    "\n",
    "log_pos_ner_acronyms_v2 = read_csv_log('./data/log_sentences_pos_ner_acronyms_v2.csv')\n",
    "text_pos_ner_acronyms_v2 = [\"\".join(t) for _,t in log_pos_ner_acronyms_v2]\n",
    "\n",
    "log_pos_VERB_ner_acronyms_lemmas = read_csv_log('./data/log_sentences_pos_VERB_ner_acronyms_lemma.csv')\n",
    "text_pos_VERB_ner_acronyms_lemmas = [\"\".join(t) for _,t in log_pos_VERB_ner_acronyms_lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing clusters with DBSCAN for each data log:\n",
    "\n",
    "inc_codes = [code for code,_ in log_dep_lemmas_root]\n",
    "cluster_dep_lemmas_root, vecmodel_dep_lemmas_root = cluster_incidences(text_dep_lemmas_root, inc_codes = inc_codes)\n",
    "\n",
    "inc_codes = [code for code,_ in log_dep_lemmas]\n",
    "cluster_dep_lemmas, vecmodel_dep_lemmas = cluster_incidences(text_dep_lemmas, inc_codes = inc_codes)\n",
    "\n",
    "inc_codes = [code for code,_ in log_pos_ner_acronyms_lemmas]\n",
    "cluster_pos_ner_acronyms_lemmas, vecmodel_pos_ner_acronyms_lemmas = cluster_incidences(text_pos_ner_acronyms_lemmas, inc_codes = inc_codes)\n",
    "\n",
    "inc_codes = [code for code,_ in log_pos_ner_acronyms]\n",
    "cluster_pos_ner_acronyms, vecmodel_pos_ner_acronyms = cluster_incidences(text_pos_ner_acronyms, inc_codes = inc_codes)\n",
    "\n",
    "inc_codes = [code for code,_ in log_pos_ner_acronyms_v2]\n",
    "cluster_pos_ner_acronyms_v2, vecmodel_pos_ner_acronyms_v2 = cluster_incidences(text_pos_ner_acronyms_v2, inc_codes = inc_codes)\n",
    "\n",
    "inc_codes = [code for code,_ in log_pos_VERB_ner_acronyms_lemmas]\n",
    "cluster_pos_VERB_ner_acronyms_lemmas, vecmodel_pos_VERB_ner_acronyms_lemmas = cluster_incidences(text_pos_VERB_ner_acronyms_lemmas, inc_codes = inc_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Dependency parsed texts (ROOT)=> Silhouette metric: 0.765413\n",
      "* Dependency parsed texts => Silhouette metric: 0.082992\n",
      "* POS (NOUN, VERB, ADJ) + NER + Acronyms + lemmas => Silhouette metric: 0.001605\n",
      "* POS (NOUN, VERB, ADJ) + NER + Acronyms => Silhouette metric: 0.027595\n",
      "* POS (NOUN, VERB, ADJ, NPROP)+ NER + Acronyms => Silhouette metric: -0.009782\n",
      "* POS (VERB) + NER + Acronyms + lemmas => Silhouette metric: 0.131110\n"
     ]
    }
   ],
   "source": [
    "# Silhouette metric for each cluster:\n",
    "\n",
    "silhouette_dep_lemmas_root = silhouette_score(vecmodel_dep_lemmas_root, list(cluster_dep_lemmas_root.values()))\n",
    "print(\"* Dependency parsed texts (ROOT)=> Silhouette metric: %f\" % silhouette_dep_lemmas_root)\n",
    "\n",
    "silhouette_dep_lemmas = silhouette_score(vecmodel_dep_lemmas, list(cluster_dep_lemmas.values()))\n",
    "print(\"* Dependency parsed texts => Silhouette metric: %f\" % silhouette_dep_lemmas)\n",
    "\n",
    "silhouette_pos_ner_acronyms_lemmas = silhouette_score(vecmodel_pos_ner_acronyms_lemmas, list(cluster_pos_ner_acronyms_lemmas.values()))\n",
    "print(\"* POS (NOUN, VERB, ADJ) + NER + Acronyms + lemmas => Silhouette metric: %f\" % silhouette_pos_ner_acronyms_lemmas)\n",
    "\n",
    "silhouette_pos_ner_acronyms = silhouette_score(vecmodel_pos_ner_acronyms, list(cluster_pos_ner_acronyms.values()))\n",
    "print(\"* POS (NOUN, VERB, ADJ) + NER + Acronyms => Silhouette metric: %f\" % silhouette_pos_ner_acronyms)\n",
    "\n",
    "silhouette_pos_ner_acronyms_v2 = silhouette_score(vecmodel_pos_ner_acronyms_v2, list(cluster_pos_ner_acronyms_v2.values()))\n",
    "print(\"* POS (NOUN, VERB, ADJ, NPROP)+ NER + Acronyms => Silhouette metric: %f\" % silhouette_pos_ner_acronyms_v2)\n",
    "\n",
    "silhouette_pos_VERB_ner_acronyms_lemmas = silhouette_score(vecmodel_pos_VERB_ner_acronyms_lemmas, list(cluster_pos_VERB_ner_acronyms_lemmas.values()))\n",
    "print(\"* POS (VERB) + NER + Acronyms + lemmas => Silhouette metric: %f\" % silhouette_pos_VERB_ner_acronyms_lemmas)    \n",
    "\n",
    "# Escribir en un archivo el clustering de dep_lemmas_root\n",
    "with open(\"./data/clustering_log5_dep_lemmas_root.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"INCIDENCECODE,CLUSTER\")\n",
    "    for code, cluster in cluster_dep_lemmas_root.items():\n",
    "        f.write(\"%s,%s\\n\" % (code, cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Creation of the new log and re-labelling of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***log_sentences_dep_lemmas_root*** contains the identifier of the incidents and their processed descriptions. The log ***clustering_log5_dep_lemmas_root*** is the result of performing a clustering task on the above-mentioned log, and contains the identifier of the incidents and the cluster number to which it has been assigned.\n",
    "\n",
    "It is necessary to join both logs in order to have the three relevant data in the same memory structure: *incident identifier, processed descriptions and assigned cluster.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences_dep_lemmas_root = pd.read_csv('./data/log_sentences_dep_lemmas_root.csv')\n",
    "df_clustering_dbscan_sentences_dep_lemmas = pd.read_csv('./data/clustering_log5_dep_lemmas_root.csv')\n",
    "df_clustering_dbscan_sentences_dep_lemmas.columns = ['INCIDENCECODE', 'CLUSTER']\n",
    "df_merged_sent_dep_lemmas = pd.merge(df_clustering_dbscan_sentences_dep_lemmas, df_sentences_dep_lemmas_root, how='left', left_on=['INCIDENCECODE'], right_on=['INCIDENCECODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracted from: https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.XoRkFXLtaUk\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        if feature_vals[idx] not in results.keys():\n",
    "            if score_vals[idx] == max(score_vals):\n",
    "                results[feature_vals[idx]] = {'max_punctuation':score_vals[idx]}\n",
    "            else:\n",
    "                results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to calculate the new labels that will be assigned to each cluster. To do this, the most representative cluster words are obtained using TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.8, ngram_range=(1,3))\n",
    "X = cv.fit_transform(df_merged_sent_dep_lemmas['DESCRIPTION'])\n",
    "#If errors of format\n",
    "#X = cv.fit_transform(df_merged_sent_dep_lemmas['DESCRIPTION'].values.astype('U'))\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "different_clusters_indexes = list(df_merged_sent_dep_lemmas['CLUSTER'].unique())\n",
    "keyword_cluster_relabelling = dict()\n",
    "\n",
    "for dci in different_clusters_indexes:\n",
    "    df_filtered = df_merged_sent_dep_lemmas[df_merged_sent_dep_lemmas['CLUSTER'] == dci]\n",
    "    docs = list(df_filtered['DESCRIPTION'])\n",
    "    #If errors of format:\n",
    "    #docs = list(df_filtered['DESCRIPTION'].values.astype('U'))\n",
    "    tfidf_vector_cluster = tfidf_transformer.transform(cv.transform(docs))\n",
    "    sorted_items_cluster = sort_coo(tfidf_vector_cluster.tocoo())\n",
    "    keywords_cluster = extract_topn_from_vector(feature_names, sorted_items_cluster, 10)\n",
    "    most_relevant_to_return = [k for k,v in keywords_cluster.items() if type(v)== dict]\n",
    "    keyword_cluster_relabelling[dci] = most_relevant_to_return[0]\n",
    "    \n",
    "keyword_cluster_relabelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that will serve to create the new column formed by the new labels is created and the new cluster is generated.\n",
    "To obtain relevant information to be included in the XES, it is necessary to add information regarding the *case* (GTI code) and the *timestamp* of each incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_label_value(row, keyword_cluster_relabelling):\n",
    "    return keyword_cluster_relabelling[row['CLUSTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_sent_dep_lemmas['LABEL'] = df_merged_sent_dep_lemmas.apply(lambda x: new_label_value(x, keyword_cluster_relabelling), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_xes_merge = df_merged_sent_dep_lemmas.filter(items=['INCIDENCECODE', 'LABEL'])\n",
    "\n",
    "new_incidence_code_no_sentences = list(df_to_xes_merge['INCIDENCECODE'])\n",
    "new_incidence_code_no_sentences = [ic.split('_')[0] if '_' in ic else ic for ic in new_incidence_code_no_sentences]\n",
    "\n",
    "df_to_xes_merge_no_ = df_to_xes_merge.copy()\n",
    "df_to_xes_merge_no_['INCIDENCECODE'] = new_incidence_code_no_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ora_complete = pd.read_csv('./data/df_ora_complete.csv')\n",
    "df_ora_complete = pd.read_sql(query, con=connection)\n",
    "df_ora_columns_needed = df_ora_complete.filter(items=['INCIDENCECODE','INCIDENCEDATE', 'GTICODE'])\n",
    "df_merged_to_ora =  pd.merge(df_to_xes_merge_no_, df_ora_columns_needed, how='left', left_on=['INCIDENCECODE'], right_on=['INCIDENCECODE'])\n",
    "df_merged_to_ora['INCIDENCECODE'] = df_merged_sent_dep_lemmas['INCIDENCECODE']\n",
    "df_merged_to_ora.to_csv('./data/log_sentences_dep_lemmas_root_relabelled.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Data Log Quality Metrics Calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import xmltodict\n",
    "from json import dumps,loads\n",
    "import xml.etree.ElementTree as xml\n",
    "from xml.etree import ElementTree\n",
    "from xml.etree.ElementTree import Element, SubElement\n",
    "from xmlr import xmlparse\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(path):\n",
    "    xml_string_xes = open(path,mode='r', encoding='utf-8').read()\n",
    "    log_xes = xmltodict.parse(xml_string_xes)\n",
    "    log_xes = loads(dumps(log_xes))\n",
    "    traces = log_xes['log']['trace']\n",
    "    new_traces = list(map(lambda x: {'id_trace': x['string']['@value'], 'events': x['event']}, traces))\n",
    "    \n",
    "    new_traces_2 = []\n",
    "    events_set=set()\n",
    "    different_per_trace= dict()\n",
    "      \n",
    "    for i in new_traces:\n",
    "        incidencecodes = []\n",
    "        new_events = []\n",
    "        for e in i['events']:\n",
    "            #Use 'int' if INCIDENCECODE are int or 'string' if they are string in the XES log.\n",
    "#             incidencecode = [d['@value'] for d in e['int'] if d['@key']=='INCIDENCECODE'][0]\n",
    "            incidencecode = [d['@value'] for d in e['string'] if d['@key']=='INCIDENCECODE'][0]\n",
    "            if incidencecode not in incidencecodes:\n",
    "                incidencecodes.append(incidencecode)\n",
    "                new_events.append([d['@value'] for d in e['string'] if d['@key']== 'concept:name'][0])\n",
    "    \n",
    "        new_traces_2.append({'id_trace':i['id_trace'], 'events':new_events})\n",
    "        events_set.update(new_events)\n",
    "        different_per_trace[i['id_trace']] = len(set(new_events))\n",
    "    \n",
    "    \n",
    "    traces_count_events = list(map(lambda x: {x['id_trace']: len(x['events'])}, new_traces_2))\n",
    "    \n",
    "    traces_count_events_dict = dict()\n",
    "    for d in traces_count_events:\n",
    "        for k,v in d.items():\n",
    "            traces_count_events_dict[k] = v\n",
    "    \n",
    "    total_events = sum([list(d.values())[0] for d in traces_count_events])\n",
    "    \n",
    "    events_dict = dict()\n",
    "    for i in new_traces_2:\n",
    "        for e in i['events']:\n",
    "            if e in events_dict.keys():\n",
    "                events_dict[e] = events_dict[e] + 1\n",
    "            else:\n",
    "                events_dict[e] = 1\n",
    "\n",
    "    lonely_events = [k for k, v in events_dict.items() if v == 1]\n",
    "    \n",
    "    lonely_events_per_trace = dict()\n",
    "\n",
    "    for d in new_traces_2:\n",
    "        lonely_events_per_trace[d['id_trace']] = len([e for e in d['events'] if e in lonely_events])\n",
    "    \n",
    "    \n",
    "    return traces_count_events_dict, lonely_events_per_trace, total_events, len(list(events_set)), len(lonely_events), len(traces_count_events_dict), total_events/len(traces_count_events_dict), different_per_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_lonely_events_events(lonely_events_per_trace, events_per_trace):\n",
    "    average_lonely_events_dict = dict()\n",
    "    for k, v in lonely_events_per_trace.items():\n",
    "        average_lonely_events_dict[k] = (v/events_per_trace[k])\n",
    "    \n",
    "    return average_lonely_events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_roughest_trace(average_lonely_events_per_trace):\n",
    "    df = pd.DataFrame()\n",
    "    df['id_trace'] = list(average_lonely_events_per_trace.keys())\n",
    "    df['average'] = list(average_lonely_events_per_trace.values())\n",
    "    average_mean = df['average'].mean()\n",
    "    df['sd'] = df.apply(lambda x: np.std([x['average'], average_mean]), axis=1)\n",
    "    return max(list(df['sd']), default=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_in_log(total_events, total_lonely_events):\n",
    "    return total_lonely_events/total_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_in_log(total_events, total_different_events):\n",
    "    return total_different_events/total_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_average(different_events_per_trace, events_per_trace):\n",
    "    diversity_events_dict = dict()\n",
    "    for k, v in different_events_per_trace.items():\n",
    "        diversity_events_dict[k] = (v/events_per_trace[k])\n",
    "    \n",
    "    return diversity_events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_disparate_trace(average_diversity_per_trace):\n",
    "    df = pd.DataFrame()\n",
    "    df['id_trace'] = list(average_diversity_per_trace.keys())\n",
    "    df['average'] = list(average_diversity_per_trace.values())\n",
    "    average_mean = df['average'].mean()\n",
    "    df['sd'] = df.apply(lambda x: np.std([x['average'], average_mean]), axis=1)\n",
    "    return max(list(df['sd']), default=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_composed_metrics(total_events, total_lonely_events, total_different_events, events_per_trace, lonely_per_trace, different_per_trace):\n",
    "    noise_in_log = get_noise_in_log(total_events, total_lonely_events)\n",
    "    average_lonely_per_trace = get_average_lonely_events_events(lonely_per_trace, events_per_trace)\n",
    "    max_noise = get_noise_roughest_trace(average_lonely_per_trace)\n",
    "    diversity_in_log = get_diversity_in_log(total_events, total_different_events)\n",
    "    average_diversity_per_trace = get_diversity_average(different_per_trace, events_per_trace)\n",
    "    max_diversity = get_diversity_disparate_trace(average_diversity_per_trace)\n",
    "    \n",
    "    return noise_in_log, max_noise, diversity_in_log, max_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(path):\n",
    "    res = get_metrics(path)\n",
    "    res_composed = get_composed_metrics(res[2], res[4], res[3], res[0], res[1], res[7])\n",
    "    print('EVENTS: ', res[2])\n",
    "    print('DIFFERENT EVENTS: ', res[3])\n",
    "    print('LONELY EVENTS: ', res[4])\n",
    "    print('TRACES: ', res[5])\n",
    "    print('COMPLEXITY: ', res[6])\n",
    "    print('NOISE IN LOG: ', res_composed[0])\n",
    "    print('NOISE MAX DEV: ', res_composed[1])\n",
    "    print('DIVERSITY IN LOG: ', res_composed[2])\n",
    "    print('DIVERSITY MAX DEV: ', res_composed[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of metrics computation\n",
    "print_metrics('./data/log_sentences_dep_lemmas_root.xes') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.- Process Quality Metrics Calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality(df_param):\n",
    "    df_param = df_param.iloc[:,1:]\n",
    "    df_param = df_param.loc[:, (df_param != 0).any()]\n",
    "    total_configurations = df_param.shape[0]\n",
    "    df_param = df_param.apply(pd.to_numeric)\n",
    "    sums = df_param.iloc[:,1:df_param.shape[1]].select_dtypes(pd.np.number).sum().rename('total')\n",
    "    total_sum = sums.sum()\n",
    "    lasagna_quality = total_sum/total_configurations\n",
    "    lasagna_quality = (df_param.shape[1]-1) - lasagna_quality\n",
    "    return lasagna_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe_from_xes_file(filepath):\n",
    "    path = filepath\n",
    "    xml_string = open(path, mode='r', encoding='utf-8').read()\n",
    "    log_is = xmltodict.parse(xml_string)\n",
    "    log_is = loads(dumps(log_is))\n",
    "    events_set = set()\n",
    "    traces = log_is['log']['trace']\n",
    "    new_traces = list(map(lambda x: {'id_trace': x['string']['@value'], 'events': x['event']}, traces))\n",
    "\n",
    "    for i in new_traces:\n",
    "        new_events = list(map(lambda x: [dictionary['@value'] for dictionary in x['string'] if dictionary['@key'] == 'concept:name'][0], i['events']))\n",
    "        i['events'] = new_events\n",
    "\n",
    "    for i in new_traces:\n",
    "        events_set.update(i['events'])\n",
    "        columns = np.array(list(events_set), dtype=object)\n",
    "    \n",
    "    traces_rows = []\n",
    "    for trace in new_traces:\n",
    "        count = 0\n",
    "        zeros = np.zeros(len(columns))\n",
    "        zeros = np.append(zeros, [trace['id_trace']])\n",
    "        for i in columns:\n",
    "            if (i in trace['events']):\n",
    "                zeros[count] = float(zeros[count])+1\n",
    "            count = count + 1\n",
    "        traces_rows.append(zeros)\n",
    "\n",
    "    traces_rows2 = list(map(lambda x: pd.Series(x), traces_rows))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat(traces_rows2, axis=1)\n",
    "    df = df.T\n",
    "    \n",
    "    columns = np.append(columns, ['id_instance'])\n",
    "    df.columns = columns\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].apply(pd.to_numeric)\n",
    "    df['id_instance'] = df['id_instance'].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataframe_from_xes_file('./data/log_sentences_dep_lemmas_root_relabelled.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_quality(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of process metrics has been done using the following Java code script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "import java.util.HashMap;\n",
    "import java.util.Map;\n",
    "\n",
    "import javax.xml.parsers.DocumentBuilder;\n",
    "import javax.xml.parsers.DocumentBuilderFactory;\n",
    "\n",
    "import org.w3c.dom.Document;\n",
    "import org.w3c.dom.Element;\n",
    "import org.w3c.dom.Node;\n",
    "import org.w3c.dom.NodeList;\n",
    "\n",
    "/***\t\n",
    " * Class to determine process metrics\n",
    " * \n",
    " * @author Ángel Jesús Varela Vaca (ajvarela@us.es)\n",
    " * @author IDEA Research Group (http://www.idea.us.es)\n",
    " * @version 1.0   \n",
    " *\n",
    " */\n",
    "\n",
    "public class testBPMN {\n",
    "\n",
    "\t/**\n",
    "\t * Main program which recevies the bpmn an print the process metrics. \n",
    "\t * @param args receive as input a bpmn file (UTF-8)\n",
    "\t * \n",
    "\t */\n",
    "\tpublic static void main(String[] args) {\n",
    "\n",
    "\t\ttry {\n",
    "\t\t\tFile inputFile = new File(\"src/main/resources/\" + args[0] + \".bpmn\");\n",
    "\n",
    "\t\t\tDocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n",
    "\t\t\tDocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n",
    "\t\t\tDocument doc = dBuilder.parse(inputFile);\n",
    "\t\t\tdoc.getDocumentElement().normalize();\n",
    "\n",
    "\t\t\tSystem.out.println(\"Root element :\" + doc.getDocumentURI());\n",
    "\n",
    "\t\t\tNodeList lSequence = doc.getElementsByTagName(\"sequenceFlow\");\n",
    "\n",
    "\t\t\tNodeList lTask = doc.getElementsByTagName(\"task\");\n",
    "\n",
    "\t\t\tNodeList lgateway = doc.getElementsByTagName(\"exclusiveGateway\");\n",
    "\n",
    "\t\t\tNodeList pgateway = doc.getElementsByTagName(\"parallelGateway\");\n",
    "\n",
    "\t\t\tNodeList loutgoings = doc.getElementsByTagName(\"outgoing\");\n",
    "\n",
    "\t\t\tMap<String, String> mtask = new HashMap<>();\n",
    "\n",
    "\t\t\tSystem.out.println(\"Number of tasks:\" + lTask.getLength());\n",
    "\n",
    "\t\t\tSystem.out.println(\"Number of sequences:\" + lSequence.getLength());\n",
    "\n",
    "\t\t\tint gateways = pgateway.getLength() + lgateway.getLength();\n",
    "\t\t\t\n",
    "\t\t\tSystem.out.println(\"Number of and:\" + pgateway.getLength());\n",
    "\n",
    "\t\t\tSystem.out.println(\"Number of exclusives:\" + lgateway.getLength());\n",
    "\n",
    "\t\t\tSystem.out.println(\"Number of gateways:\" + gateways);\n",
    "\n",
    "\t\t\tSystem.out.println(\"Number of outgoings (CFC):\" + loutgoings.getLength());\n",
    "\n",
    "\t\t\tfor (int temp = 0; temp < lTask.getLength(); temp++) {\n",
    "\t\t\t\tNode nNode = lTask.item(temp);\n",
    "\t\t\t\tElement eElement = (Element) nNode;\n",
    "\n",
    "\t\t\t\tmtask.put(eElement.getAttribute(\"name\"), eElement.getAttribute(\"id\"));\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tint contador = 0;\n",
    "\t\t\tfor (int i = 0; i < lSequence.getLength(); i++) {\n",
    "\t\t\t\tNode n = lSequence.item(i);\n",
    "\t\t\t\tElement eElement = (Element) n;\n",
    "\n",
    "\t\t\t\tboolean nsource = mtask.values().contains(eElement.getAttribute(\"sourceRef\"));\n",
    "\t\t\t\tboolean ntarget = mtask.values().contains(eElement.getAttribute(\"targetRef\"));\n",
    "\n",
    "\t\t\t\tif (nsource && ntarget) {\n",
    "\t\t\t\t\tcontador += 1;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tSystem.out.println(\"Arcs betwee none-connector nodes:\" + contador);\n",
    "\t\t\tfloat seq = (float) contador/lSequence.getLength();\n",
    "\t\t\tSystem.out.println(\"Sequentiality:\" + String.format(\"%,.10f\", seq));\n",
    "\n",
    "\t\t} catch (Exception e) {\n",
    "\t\t\te.printStackTrace();\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
